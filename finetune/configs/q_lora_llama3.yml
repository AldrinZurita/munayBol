# QLoRA config ejemplo para Llama 3 Instruct 8B (Axolotl)
# Ajusta rutas, batch sizes y epochs según tu hardware

model_name: meta-llama/Meta-Llama-3-8B-Instruct
load_in_4bit: true
bnb_4bit_compute_dtype: float16
use_lora: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05

# Dataset
# Cambia la ruta a tu dataset real
# Tipo "alpaca" para {instruction, input, output}

dataset_mixer:
  - path: finetune/dataset/data.jsonl
    type: alpaca
    weight: 1.0

# Entrenamiento básico
training:
  micro_batch_size: 2
  gradient_accumulation_steps: 8
  epochs: 2
  learning_rate: 2e-4
  max_seq_len: 4096
  save_steps: 200

# Salida
output_dir: finetune/outputs/llama3-8b-munaybol-lora
